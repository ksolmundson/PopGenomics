##NGSAdmix ##

## run NGSAdmix on Compute Canada ##

# submit as a loop 
for k in $(cat klist.txt)
do
echo ${k}
sbatch NGSadmix.sh ${k}
sleep 10
done

##to the bash script file called "NGSadmix.sh" add #SBATCH --array=1-10 to perform 10 runs at each K
module load angsd/0.936
NGSadmix -likes midhigh_autosomes_filter_final_more.recode.beagle.gz -K ${1} -o midhigh_K${1} -P 12

#####################################
#convert the .qopt file to a csv and add ID column before importing the data
#then plot in R

library(tidyverse)

#example for K=2
#load the data
admix2 = read_csv("midhigh_K2_1.csv", col_names = T)

#make the plot
plot2 = barplot(t(as.matrix(subset(admix2, select=q1:q2))), names.arg = admix2$ID, las=2, col=c("#61342A","#175676"), cex.names=0.75, border=NA, , ylab = "Proportion")
title(xlab = "Caribou ID", line=4)

#then compare log likelihood values across all runs at each K value
#script modified from: https://baylab.github.io/MarineGenomics/week-9-population-structure-using-ngsadmix.html

#import the .log files in R
data <- list.files("C:/path/NGSadmix_midhigh/", pattern = ".log", full.names=T)
data 

#loop over all 10 runs at each K value (K=2-9 --> total of 80 runs)
bigData <- lapply(1:80, FUN = function(i) readLines(data[i]))

library(stringr)
foundset<-sapply(1:80, FUN= function(x) bigData[[x]][which(str_sub(bigData[[x]], 1, 1) == 'b')])

foundset

as.numeric( sub("\\D*(\\d+).*", "\\1", foundset) )

logs<-data.frame(K = rep(2:9, each=10))

logs$like<-as.vector(as.numeric( sub("\\D*(\\d+).*", "\\1", foundset) ))

#and now we can calculate our delta K and probability
tapply(logs$like, logs$K, FUN= function(x) mean(abs(x))/sd(abs(x)))

#the largest probability value indicates the best K value
